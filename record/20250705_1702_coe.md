# coe

`成功加载模型权重: CNN/can_net_cp_0.2_20_pruned.pth`

`开始提取和量化权重...`
  - `处理层: conv_layers.0.weight, 形状: torch.Size([8, 3, 3, 3])`
  - `处理层: conv_layers.2.weight, 形状: torch.Size([32, 8, 3, 3])`
  - `处理层: fc_layers.0.weight, 形状: torch.Size([16, 288])`
  - `处理层: fc_layers.2.weight, 形状: torch.Size([2, 16])`

`所有权重提取并量化完成，总权重数量: 7160 个。`
`正在生成 coe_files\weight_bank_0.coe...`
`正在生成 coe_files\weight_bank_1.coe...`
`正在生成 coe_files\weight_bank_2.coe...`
`正在生成 coe_files\weight_bank_3.coe...`
`正在生成 coe_files\weight_bank_4.coe...`
`正在生成 coe_files\weight_bank_5.coe...`
`正在生成 coe_files\weight_bank_6.coe...`
`正在生成 coe_files\weight_bank_7.coe...`

`成功！ 8 个.coe文件已生成在 'coe_files' 目录下。`
`每个Bank的深度（行数）为: 895`
**这个脚本有问题，最后一层的权重是16×2，均分到8个bank，应该放到前两个bank里**
## fix
**collect_and_dispatch()**	提取每一层权重时，按照 “输出通道 (out-channel) → bank” 的规则分配：
 - 如果该层 out_channels ≥ 8，仍旧 0 - 7 轮转；
 - 如果 out_channels < 8（例如最后一层 2×16），只用前 out_channels 个 bank，不再稀释到 8 个 bank 里。
`模型权重加载完毕。`
`[✔] coe_files\weight_bank_0.coe 深度 = 907`
`[✔] coe_files\weight_bank_1.coe 深度 = 907`
`[✔] coe_files\weight_bank_2.coe 深度 = 907`
`[✔] coe_files\weight_bank_3.coe 深度 = 907`
`[✔] coe_files\weight_bank_4.coe 深度 = 907`
`[✔] coe_files\weight_bank_5.coe 深度 = 907`
`[✔] coe_files\weight_bank_6.coe 深度 = 907`
`[✔] coe_files\weight_bank_7.coe 深度 = 907`

`全部完成！`
907 = 每 Bank 需要存放的 总 int8 权重条目数

|     | 步骤   | 说明                | 结果    |
| --- | ---- | ----------------- | ----- |
| 1   | 卷积-1 | 3 × 3 × 3 × 8     | 224   |
| 2   | 卷积-2 | 3 × 3 × 8 × 32    | 2 336 |
| 3   | FC-1 | (32 × 3 × 3) × 16 | 4 624 |
| 4   | FC-2 | 16 × 2            | 32    |
| 总量  |      |                   | 7 216 |

7 216 ÷ 8 (个 bank) = 902 余 0 …          实际分发后：
Bank0–Bank7 ≈ 902 ± 几条（因为层数并不是 8 的整数倍）
Bank-0、1 比其他 Bank 多拿到了 Conv/FC 末尾溢出的那几条，于是最大深度成为 907，脚本会把所有 Bank 都用 0 补到 907，Vivado 才能一次性接收。

如果 FPGA 侧的 BRAM 深度固定为 2 048 / 1 024，只需把脚本里

python
Copy
Edit
depth_max = max(len(b) for b in banks)
替换成你希望的深度（例如 2048），程序会自动继续在每 bank 末尾补 0 直至满足要求。

⚠️ 深度只能 ≥907；若设得比 907 小就会丢权重！

常见下一步
目标
