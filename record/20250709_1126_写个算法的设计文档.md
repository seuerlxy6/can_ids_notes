```markdown
# CAN-RGB + CANET-33K 入侵检测设计文档  
> 目标：给已有机器学习 / 嵌入式背景的研究生，一周内跑通并复现本文的方法与结果  
> 范围：数据预处理 → RGB 编码 → 轻量 CNN 设计 → 一次性剪枝 + INT8 PTQ → 评估  

---

## 0. 先决条件
| 类别 | 版本 / 说明 |
|------|-------------|
| Python | ≥ 3.9 |
| PyTorch | ≥ 2.1（需 `torch.ao.quantization`） |
| CUDA | 11.x（如无 GPU 可走 CPU） |
| 依赖 | `pip install -r requirements.txt`，核心：numpy / pandas / seaborn / scikit-learn / onnxruntime |

---

## 1. 数据集与目录结构

```
# CAN-RGB + CANET-33K 入侵检测设计文档  
> 目标：给已有CAN总线 / 神经网络背景的研究生
> 范围：数据预处理 → RGB 编码 → 轻量 CNN 设计 → 一次性剪枝 + INT8 PTQ → 评估  
> 
---

## 0. 先决条件
| 类别 | 版本 / 说明 |
|------|-------------|
| Python | ≥ 3.9 |
| PyTorch | ≥ 2.1（需 `torch.ao.quantization`） |
| CUDA | 11.x（如无 GPU 可走 CPU） |
| 依赖 | `pip install -r requirements.txt`，核心：numpy / pandas / seaborn / scikit-learn / onnxruntime |

---

## 1. 数据集与目录结构
├─dataset_hack(原始数据集)[HCRL - Car-Hacking Dataset](https://ocslab.hksecurity.net/Datasets/car-hacking-dataset)
│  ├─dataset_hack（生成的图片和标签）
│  │  ├─DoS_dataset_img_hack
│  │  │  └─can_images
│  │  │  └─label.csv
│  │  ├─Fuzzy_dataset_img_hack
│  │  │  └─can_images
│  │  │  └─label.csv
│  │  ├─gear_dataset_img_hack
│  │  │  └─can_images
│  │  │  └─label.csv
│  │  └─RPM_dataset_img_hack
│  │      └─can_images
│  │  │  └─label.csv
│  ├─runs
├─runs
│  └─RGBA
│      └─cannet_0.2_20
│          ├─Accuracy_Train
│          ├─Accuracy_Val
│          ├─Loss_Train
│          └─Loss_Val
├─runs_20epoch_rgb_all_data
│  └─can_net_training
│      ├─Accuracy_Train
│      ├─Accuracy_Val
│      ├─Loss_Train
│      └─Loss_Val
├─seq
│  ├─modified_data
│  ├─runs
│  │  ├─can_net_training
│  │  │  ├─Accuracy_Train
│  │  │  ├─Accuracy_Val
│  │  │  ├─Loss_Train
│  │  │  └─Loss_Val
│  │  └─can_net_training_new
│  ├─unable
│  └─__pycache__
├─seq-can-train-test
├─unable
└─__pycache__

````
> **数据标准**  
> | 字段 | 位宽 | 说明 |  
> |------|------|------|  
> | `timestamp` | 64 bit | us 级采样时间戳 |  
> | `id`        | 11/29 bit | CAN 标识符 |  
> | `dlc`       | 4 bit | 数据长度码 |  
> | `data`      | ≤ 64 bit | 以字节序列存储 |

---

## 2. CAN-RGB 编码  
核心思路：把 *时间*、*ID*、*DLC* 三个维度塞进一张 64 × 64 × 3 的图。

| 通道 | 填充值 | 归一化策略 |
|------|--------|-----------|
| **R** | `timestamp Δt` (μs) | log-minmax (剪长尾) |
| **G** | 标识符 ID | /2048 (11-bit) |
| **B** | DLC | /8 |

伪码：
```python
def encode_window(df):
    r = log_norm(np.diff(df['timestamp'], prepend=df['timestamp'].iloc[0]))
    g = df['id'].astype(np.float32) / 2048
    b = df['dlc'].astype(np.float32) / 8
    img = np.stack([r, g, b], axis=-1)      # shape (N, 3)
    return img.reshape(64, 64, 3)           # N=4096
````

---

## 3. 基线网络 CANET-33K

```
Conv(3,8,k3) → BN+ReLU
Conv(8,32,k3,stride2) → BN+ReLU
MaxPool(2)
FC(32*3*3 → 16) → ReLU
FC(16 → 2)
```

- 总参数：32 960 ≈ 33 k
    
- FLOPs：2.31 M
    
- PyTorch 定义见 `models/canet.py`
    

---

## 4. 一次性混合压缩

### 4.1 结构化剪枝

- 目标稀疏率：50 % 通道级
    
- 方法：`torch.nn.utils.prune.ln_structured`
    
- 剪枝后参数 ↓ 到 **14 416**
    

### 4.2 INT8 Post-Training Quantisation

```python
backend = 'fbgemm'
model.eval()
qconfig = torch.ao.quantization.get_default_qconfig(backend)
qmodel  = torch.ao.quantization.quantize_dynamic(
            model, {nn.Linear}, dtype=torch.qint8)
```

- 参数尺寸：**7 208**
    
- 存储：**17.05 kB**
    
- 精度保持：99.72 %
    

---

## 5. 训练-剪枝-量化流水线

```bash
python scripts/00_rgb_encode.py   # 原始 CAN → .npy
python scripts/10_train_fp32.py   # 20 epochs baseline
python scripts/20_prune.py        # 50 % structured
python scripts/30_ptq_int8.py     # dynamic quant
python scripts/40_eval.py         # 报告 ACC / F1 / ROC
```

输出示例：

```
FP32  : acc 99.89 | params 32.9k
Prune : acc 99.78 | params 14.4k
INT8  : acc 99.72 | params 7.2k  (17.05 kB)
```

---

## 6. 结果复现与可视化

- 混淆矩阵、ROC、PR 曲线均自动保存到 `results/figs/`
    
- `tensorboard --logdir runs` 查看 loss / lr / sparsity 变化
    
- 10-fold cross-vehicle split 配置见 `config/split_*.json`
    

---

## 7. 推理性能基准

|环境|延迟 / 样本|备注|
|---|---|---|
|Ryzen 5800H (FP32)|0.68 ms|torch + ONNX|
|同 CPU (INT8)|0.42 ms|onnxruntime|
|NVIDIA RTX 3060|0.11 ms|fp16 TensorCore|

> **结论**：INT8 在 CPU 侧仅 1.6× 提升；真正收益将在硬件侧体现。

---

## 8. 未来工作

1. **QAT**：量化感知训练，预期 +0.1 pp 精度，INT8 推理更鲁棒。
    
2. **更深剪枝**：探索 70–80 % 稀疏率与 Lottery Ticket style 微调。
    
3. **Domain shift**：跨车型、跨路况增量学习。
    
4. **公开硬件接口**：发布 AXI-stream 数据包 + Verilog 参考，以便快速硬件-in-loop。
    

---

## 9. 参考实现

- `repo_url`：[https://github.com/yourname/CANET-RGB](https://github.com/yourname/CANET-RGB)  
    分支 `lite-fpga` 持续更新
    
- Issues / PR welcome.
    

```

> 复制整份 Markdown 即可放进项目根 README 或内部 Wiki。
```